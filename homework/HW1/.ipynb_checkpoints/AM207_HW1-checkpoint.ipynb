{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2 (Due 09/17/2020, 11:59pm)\n",
    "## Maximum Likelihood Learning and Bayesian Inference\n",
    "\n",
    "**AM 207: Advanced Scientific Computing**<br>\n",
    "**Instructor: Weiwei Pan**<br>\n",
    "**Fall 2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:**\n",
    "\n",
    "**Students collaborators:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "**Submission Format:** Use this notebook as a template to complete your homework. Please intersperse text blocks (using Markdown cells) amongst `python` code and results -- format your submission for maximum readability. Your assignments will be graded for correctness as well as clarity of exposition and presentation -- a “right” answer by itself without an explanation or is presented with a difficult to follow format will receive no credit.\n",
    "\n",
    "**Code Check:** Before submitting, you must do a \"Restart and Run All\" under \"Kernel\" in the Jupyter or colab menu. Portions of your submission that contains syntactic or run-time errors will not be graded.\n",
    "\n",
    "**Libraries and packages:** Unless a problems specifically asks you to implement from scratch, you are welcomed to use any `python` library package in the standard Anaconda distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "In the competitive rubber chicken retail market, the success of a company is built on satisfying the exacting standards of a consumer base with refined and discriminating taste. In particular, customer product reviews are all important. But how should we judge the quality of a product based on customer reviews?\n",
    "\n",
    "On Amazon, the first customer review statistic displayed for a product is the ***average rating***. The following are the main product pages for two competing rubber chicken products, manufactured by Lotus World and Toysmith respectively:\n",
    "\n",
    "\n",
    "Lotus World |  Toysmith\n",
    "- |  - \n",
    "![alt](lotus1.png) |  ![alt](toysmith1.png)\n",
    "\n",
    "Clicking on the 'customer review' link on the product pages takes us to a detailed break-down of the reviews. In particular, we can now see the number of times a product is rated a given rating (between 1 and 5 stars).\n",
    "\n",
    "Lotus World |  Toysmith\n",
    "- |  - \n",
    "![alt](lotus2.png) |  ![alt](toysmith2.png)\n",
    "\n",
    "\n",
    "In the following, we will ask you to build statistical models to compare these two products using the observed rating. Larger versions of the images are available in the data set accompanying this notebook.\n",
    "\n",
    "\n",
    "\n",
    "## Part I: A Maximum Likelihood Model\n",
    "1. **(Model Building)** Suppose that for each product, we can model the probability of the value each new rating as the following vector:\n",
    "$$\n",
    "\\theta = [\\theta_1, \\theta_2, \\theta_3, \\theta_4, \\theta_5]\n",
    "$$\n",
    "  where $\\theta_i$ is the probability that a given customer will give the product $i$ number of stars. That is, each new rating (a value between 1 and 5) has a categorical distribution $Cat(\\theta)$. Represent the observed ratings of an Amazon product as a vector $R = [r_1, r_2, r_3, r_4, r_5]$ where, for example, $r_4$ is the number of $4$-star reviews out of a total of $N$ ratings. Write down the likelihood of $R$. That is, what is $p(R| \\theta)$?\n",
    "\n",
    "  **Note:** The observed ratings for each product should be read off the image files included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **(Model Fitting)** Find the maximum likelihood estimator of $\\theta$ for the Lotus World model; find the MLE of $\\theta$ for the Toysmith model. You need to make a reasonably mathematical argument for why your estimate actually maximizes the likelihood (i.e. recall the criteria for a point to be a global optima of a function).\n",
    "\n",
    "  *Note:* I recommend deriving the MLE using the general expression of the likelihood. That is, derive the posterior using the variable $R$, then afterwards plug in your specific values of $R$ for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **(Model Interpretation)** Based on your MLE of $\\theta$'s for both models, do you feel confident deciding if one product is superior to another? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: A Bayesian Model\n",
    "\n",
    "1. **(Model Building)** Suppose you are told that customer opinions are very polarized in the retail world of rubber chickens, that is, most reviews will be 5 stars or 1 stars (with little middle ground). What would be an appropriate $\\alpha$ for the Dirichlet prior on $\\theta$? Recall that the Dirichlet pdf is given by:\n",
    "$$\n",
    "p_{\\Theta}(\\theta) = \\frac{1}{B(\\alpha)} \\prod_{i=1}^k \\theta_i^{\\alpha_i - 1}, \\quad B(\\alpha) = \\frac{\\prod_{i=1}^k\\Gamma(\\alpha_i)}{\\Gamma\\left(\\sum_{i=1}^k\\alpha_i\\right)},\n",
    "$$\n",
    "where $\\theta_i \\in (0, 1)$ and $\\sum_{i=1}^k \\theta_i = 1$, $\\alpha_i > 0 $ for $i = 1, \\ldots, k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **(Inference)** Analytically derive the posterior distribution (using the likelihoods you derived in Part I) for each product.\n",
    "\n",
    "  *Note:* I recommend deriving the posterior using the general expression of a Dirichelet pdf. That is, derive the posterior using the variable $\\alpha$, then afterwards plug in your specific values of $\\alpha$ when you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **(The Maximum A Posterior Estimate)** Analytically or empirically compute the MAP estimate of $\\theta$ for each product, using the $\\alpha$'s you chose in Problem 1. How do these estimates compare with the MLE? Just for this problem, compute the MAP estimate of $\\theta$ for each product using a Dirichelet prior with hyperparameters $\\alpha = [1, 1, 1, 1, 1]$. Make a conjecture about the effect of the prior on the difference between the MAP estimates and the MLE's of $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **(The Posterior Mean Estimate)** Analytically or empirically compute the posterior mean estimate of $\\theta$ for each product, using the $\\alpha$'s you chose in Problem 1. How do these estimates compare with the MAP estimates and the MLE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **(The Posterior Predictive Estimate)** Sample 1000 rating vectors from the posterior predictive for each product, using the $\\alpha$'s you chose in Problem 1. Use the average of the posterior predictive samples to estimate $\\theta$. How do these estimates compare with the MAP, MLE, posterior mean estimate of $\\theta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **(Model Evaluation)** Compute the 95% credible interval of $\\theta$ for each product (*Hint: compute the 95% credible interval for each $\\theta_i$, $i=1, \\ldots, 5$*). For which product is the posterior mean and MAP estimate more reliable and why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Comparison\n",
    "1. **(Summarizing Customer Ratings)** Recall that on Amazon, the first customer review statistic displayed for a product is the average rating. Name at least one problem with ranking products based on the average customer rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **(Comparison of Point Estimates)** Which point estimate (MAP, MLE, posterior mean or posterior predictive estimate) of $\\theta$, if any, would you feel choose to rank the two Amazon products? Why? \n",
    "\n",
    "  *Hint: think about which of these estimates are equivalent (if any). If they are not equivalent, what are the special properties of each estimate? What aspect of the data or the model is each estimate good at capturing?*\n",
    "  \n",
    "   **Note:** we're not looking for \"the correct answer\" here. We are looking for a sound decision based on a statistically correct interpretation of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
